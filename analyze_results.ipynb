{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d1f99-9cc1-4eb8-a471-45be336f07a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "def balance_data(x,y):\n",
    "\n",
    "    minor_index = int(y.mean()>0.5)\n",
    "    minor_x = x[y==minor_index]\n",
    "    major_x = x[y!=minor_index]\n",
    "\n",
    "    minor_upsample = resample(minor_x,\n",
    "                 replace=True,\n",
    "                 n_samples=len(major_x),\n",
    "                 random_state=42)\n",
    "    upsampled_x = pd.concat([major_x, minor_upsample])\n",
    "    upsampled_y = np.array(len(major_x)*[1-minor_index]+len(minor_upsample)*[minor_index])\n",
    "    upsampled_x,upsampled_y = shuffle(upsampled_x,upsampled_y)\n",
    "    return upsampled_x,upsampled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041eb90-8e0f-409b-a6f8-9ad0243c296c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base = pd.read_csv('sofa_parameters.csv').reset_index(names=['id'])\n",
    "\n",
    "cols2 = [\n",
    "    'id',\n",
    "    'insurance',\n",
    "    'marital_status',\n",
    "    'race',\n",
    "    'gender',\n",
    "    'admission_age',\n",
    "    'weight',\n",
    "    'height',\n",
    "    'charlson_comorbidity_index',\n",
    "    '30d_mortality_status']\n",
    "resp= ['respiration_SOFA_d1',\n",
    "    'respiration_SOFA_d2',\n",
    "    'respiration_SOFA_d3',\n",
    "    'respiration_SOFA_d4',\n",
    "    'respiration_SOFA_d5',\n",
    "    'respiration_SOFA_d6',\n",
    "    'respiration_SOFA_d7',\n",
    "    'respiration_SOFA_d8',\n",
    "    'respiration_SOFA_d9',\n",
    "    'respiration_SOFA_d10',\n",
    "    'respiration_SOFA_d11',\n",
    "    'respiration_SOFA_d12',\n",
    "    'respiration_SOFA_d13',\n",
    "    'respiration_SOFA_d14']\n",
    "coag =['coagulation_SOFA_d1',\n",
    "    'coagulation_SOFA_d2',\n",
    "    'coagulation_SOFA_d3',\n",
    "    'coagulation_SOFA_d4',\n",
    "    'coagulation_SOFA_d5',\n",
    "    'coagulation_SOFA_d6',\n",
    "    'coagulation_SOFA_d7',\n",
    "    'coagulation_SOFA_d8',\n",
    "    'coagulation_SOFA_d9',\n",
    "    'coagulation_SOFA_d10',\n",
    "    'coagulation_SOFA_d11',\n",
    "    'coagulation_SOFA_d12',\n",
    "    'coagulation_SOFA_d13',\n",
    "    'coagulation_SOFA_d14']\n",
    "liver= ['liver_SOFA_d1',\n",
    "    'liver_SOFA_d2',\n",
    "    'liver_SOFA_d3',\n",
    "    'liver_SOFA_d4',\n",
    "    'liver_SOFA_d5',\n",
    "    'liver_SOFA_d6',\n",
    "    'liver_SOFA_d7',\n",
    "    'liver_SOFA_d8',\n",
    "    'liver_SOFA_d9',\n",
    "    'liver_SOFA_d10',\n",
    "    'liver_SOFA_d11',\n",
    "    'liver_SOFA_d12',\n",
    "    'liver_SOFA_d13',\n",
    "    'liver_SOFA_d14']\n",
    "card=['cardiovascular_SOFA_d1',\n",
    "    'cardiovascular_SOFA_d2',\n",
    "    'cardiovascular_SOFA_d3',\n",
    "    'cardiovascular_SOFA_d4',\n",
    "    'cardiovascular_SOFA_d5',\n",
    "    'cardiovascular_SOFA_d6',\n",
    "    'cardiovascular_SOFA_d7',\n",
    "    'cardiovascular_SOFA_d8',\n",
    "    'cardiovascular_SOFA_d9',\n",
    "    'cardiovascular_SOFA_d10',\n",
    "    'cardiovascular_SOFA_d11',\n",
    "    'cardiovascular_SOFA_d12',\n",
    "    'cardiovascular_SOFA_d13',\n",
    "    'cardiovascular_SOFA_d14']\n",
    "cns=['cns_SOFA_d1',\n",
    "    'cns_SOFA_d2',\n",
    "    'cns_SOFA_d3',\n",
    "    'cns_SOFA_d4',\n",
    "    'cns_SOFA_d5',\n",
    "    'cns_SOFA_d6',\n",
    "    'cns_SOFA_d7',\n",
    "    'cns_SOFA_d8',\n",
    "    'cns_SOFA_d9',\n",
    "    'cns_SOFA_d10',\n",
    "    'cns_SOFA_d11',\n",
    "    'cns_SOFA_d12',\n",
    "    'cns_SOFA_d13',\n",
    "    'cns_SOFA_d14']\n",
    "renal=['renal_SOFA_d1',\n",
    "    'renal_SOFA_d2',\n",
    "    'renal_SOFA_d3',\n",
    "    'renal_SOFA_d4',\n",
    "    'renal_SOFA_d5',\n",
    "    'renal_SOFA_d6',\n",
    "    'renal_SOFA_d7',\n",
    "    'renal_SOFA_d8',\n",
    "    'renal_SOFA_d9',\n",
    "    'renal_SOFA_d10',\n",
    "    'renal_SOFA_d11',\n",
    "    'renal_SOFA_d12',\n",
    "    'renal_SOFA_d13',\n",
    "    'renal_SOFA_d14']\n",
    "sofa_ds = [\n",
    "    'SOFA_d1',\n",
    "    'SOFA_d2',\n",
    "    'SOFA_d3',\n",
    "    'SOFA_d4',\n",
    "    'SOFA_d5',\n",
    "    'SOFA_d6',\n",
    "    'SOFA_d7',\n",
    "    'SOFA_d8',\n",
    "    'SOFA_d9',\n",
    "    'SOFA_d10',\n",
    "    'SOFA_d11',\n",
    "    'SOFA_d12',\n",
    "    'SOFA_d13',\n",
    "    'SOFA_d14'\n",
    "]\n",
    "delta=['delta1_2',\n",
    "    'delta2_3',\n",
    "    'delta3_4',\n",
    "    'delta4_5',\n",
    "    'delta5_6',\n",
    "    'delta6_7',\n",
    "    'delta7_8',\n",
    "    'delta8_9',\n",
    "    'delta9_10',\n",
    "    'delta10_11',\n",
    "    'delta11_12',\n",
    "    'delta12_13',\n",
    "    'delta13_14']\n",
    "auc=['Area1_2',\n",
    "    'Area2_3',\n",
    "    'Area3_4',\n",
    "    'Area4_5',\n",
    "    'Area5_6',\n",
    "    'Area6_7',\n",
    "    'Area7_8',\n",
    "    'Area8_9',\n",
    "    'Area9_10',\n",
    "    'Area10_11',\n",
    "    'Area11_12',\n",
    "    'Area12_13',\n",
    "    'Area13_14']\n",
    "\n",
    "def build_set(val,n):\n",
    "    n=n-2\n",
    "    if n % 2 == 0:\n",
    "        buffer_pre = (['┌']+['│']*int(n/2-1))\n",
    "        buffer_post = (['│']*int(n/2)+['└'])\n",
    "    else:\n",
    "        buffer_pre = (['┌']+['│']*int((n-1)/2))\n",
    "        buffer_post = (['│']*int((n-1)/2)+['└'])\n",
    "    return buffer_pre,buffer_post\n",
    "\n",
    "accs = {}\n",
    "baccs = {}\n",
    "f1s = {}\n",
    "prs = {}\n",
    "recs = {}\n",
    "rocs = {}\n",
    "cms = {}\n",
    "count = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339d70b-af7d-4fa2-9c45-acb4a4df5f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in [3,8]:\n",
    "    count = count + 1\n",
    "    sofa_cols = sofa_ds[0:n+1]\n",
    "    param_list =[*resp[0:n+1], *coag[0:n+1], *liver[0:n+1], *card[0:n+1], *cns[0:n+1],\n",
    "                 *renal[0:n+1], *sofa_cols, *delta[0:n], *auc[0:n]]\n",
    "    \n",
    "    df_dofas = df_base[['id',*sofa_cols]].copy()\n",
    "    df_dofas = df_dofas.dropna(how='all', subset = sofa_cols) \n",
    "    \n",
    "    df = df_base[[\n",
    "        'id',*cols2,*param_list\n",
    "    ]].copy()\n",
    "    \n",
    "    df.loc[:,'TotalAUC'] = df[auc[0:n]].sum(axis=1)\n",
    "    df.loc[:,'SOFA_max'] = df_dofas[sofa_cols].max(axis=1)\n",
    "    df.loc[:,'SOFA_min'] = df_dofas[sofa_cols].min(axis=1)\n",
    "    def f(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        return int(x.replace('SOFA_d',''))\n",
    "    df.loc[:,'SOFA_max_day'] = df_dofas[sofa_cols].idxmax(axis=1,skipna=True).apply(lambda x: f(x))\n",
    "    df.loc[:,'SOFA_min_day'] = df_dofas[sofa_cols].idxmin(axis=1,skipna=True).apply(lambda x: f(x))\n",
    "    \n",
    "    df.loc[:,'SOFA_range'] = df['SOFA_max_day']-df['SOFA_min_day']\n",
    "    df.loc[:,'SOFA_long_stay'] = (~df_dofas[sofa_cols].isna()).sum(axis=1)\n",
    "\n",
    "    merge_list = ['Respiration','Coagulation','Liver', 'Cardiovascular', 'CNS', 'Renal', 'SOFA']\n",
    "    merge_list_calc = ['Delta', 'Sum']\n",
    "    tick_list = cols2[1:-1]\n",
    "    for item_list in merge_list:\n",
    "        buffer_pre,buffer_post = build_set(item_list,n+1)\n",
    "        tick_list = [*tick_list,*buffer_pre,item_list,*buffer_post]\n",
    "    for item_list in merge_list_calc:\n",
    "        buffer_pre,buffer_post = build_set(item_list,n)\n",
    "        tick_list = [*tick_list,*buffer_pre,item_list,*buffer_post]\n",
    "\n",
    "    tick_list=[*tick_list,'TotalAUC','SOFA_max','SOFA_min','SOFA_max_day','SOFA_min_day','SOFA_range','SOFA_long_stay']\n",
    "    df = df.fillna(0).reset_index()\n",
    "    \n",
    "    le = {}\n",
    "    for k in ['insurance','marital_status','race','gender']:\n",
    "        le[k] = LabelEncoder()\n",
    "        df[k] = le[k].fit_transform(df[k].astype(str))\n",
    "    \n",
    "    x = df.drop(columns=['id','id','index','30d_mortality_status'])\n",
    "    y = df['30d_mortality_status']\n",
    "    \n",
    "    feat_set = list(x.columns)\n",
    "    feat_dic = {j:i for i,j in enumerate(feat_set)}\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    feat_list = []\n",
    "    feature_importances_list = []\n",
    "    accs[count] = []\n",
    "    accs_eff = []\n",
    "    baccs[count] = []\n",
    "    f1s[count] = []\n",
    "    prs[count] = []\n",
    "    recs[count] = []\n",
    "    rocs[count] = []\n",
    "    cms[count] = []\n",
    "    \n",
    "    for i_try in range(5):\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            x_train,y_train = balance_data(x_train,y_train)\n",
    "            \n",
    "            clf = RandomForestClassifier()\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            pr = precision_score(y_test,y_pred)\n",
    "            rec = recall_score(y_test,y_pred)\n",
    "            roc = roc_auc_score(y_test,y_pred)\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            \n",
    "            accs[count].append(acc)\n",
    "            accs_eff.append(acc)\n",
    "            baccs[count].append(bacc)\n",
    "            f1s[count].append(f1)\n",
    "            prs[count].append(pr)\n",
    "            recs[count].append(rec)\n",
    "            rocs[count].append(roc)\n",
    "            cms[count].append(cm)\n",
    "            \n",
    "            feat_list.extend(feat_set)\n",
    "            feature_importances_list.append(clf.feature_importances_)\n",
    "            accs_eff.append(clf.score(x_test,y_test))\n",
    "    \n",
    "    feat_x = [feat_dic[i] for i in feat_list]\n",
    "    print(n, np.mean(accs_eff),np.std(accs_eff))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=np.mean(np.array(cms[count]),axis=(0)).astype(int),display_labels=[0,1])\n",
    "    disp.plot()\n",
    "    plt.savefig('images/cm_all{}.tif'.format(n),dpi=300)\n",
    "    ;\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(18,6))\n",
    "    ax.scatter(feat_x,feature_importances_list,marker='.')\n",
    "    ax.set_ylabel('feature importances')\n",
    "    ax.set_xticks(np.arange(len(feat_set)))\n",
    "    ax.set_xticklabels(tick_list, rotation=90)\n",
    "    ax.set_xlim(-0.5,len(feat_set)-0.5)\n",
    "    \n",
    "    title = ''\n",
    "    title += f'acc={np.mean(accs_eff):.2f}({np.std(accs_eff):.2f}), '\n",
    "    title += f'balanced acc={np.mean(baccs[count]):.2f}({np.std(baccs[count]):.2f}), '\n",
    "    title += f'f1={np.mean(f1s[count]):.2f}({np.std(f1s[count]):.2f})\\n'\n",
    "    title += f'precision={np.mean(prs[count]):.2f}({np.std(prs[count]):.2f}), '\n",
    "    title += f'recall={np.mean(recs[count]):.2f}({np.std(recs[count]):.2f}), '\n",
    "    title += f'ROC={np.mean(rocs[count]):.2f}({np.std(rocs[count]):.2f})'\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    plt.subplots_adjust(bottom=0.36)\n",
    "    plt.savefig('images/set_all{}.tif'.format(n),dpi=300)\n",
    "    ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33af45-753c-4100-82d4-77445f9bac97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in [3,8]:\n",
    "    count = count + 1\n",
    "    sofa_cols = sofa_ds[0:n+1]\n",
    "    param_list =sofa_cols\n",
    "    \n",
    "    df_dofas = df_base[['id',*sofa_cols]].copy()\n",
    "    df_dofas = df_dofas.dropna(how='all', subset = sofa_cols) \n",
    "    \n",
    "    df = df_base[[\n",
    "        'id',*cols2,*param_list\n",
    "    ]].copy()\n",
    "    \n",
    "    df.loc[:,'TotalAUC'] = df_base[auc[0:n]].sum(axis=1)\n",
    "    df.loc[:,'SOFA_max'] = df_dofas[sofa_cols].max(axis=1)\n",
    "    df.loc[:,'SOFA_min'] = df_dofas[sofa_cols].min(axis=1)\n",
    "    def f(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        return int(x.replace('SOFA_d',''))\n",
    "    df.loc[:,'SOFA_max_day'] = df_dofas[sofa_cols].idxmax(axis=1,skipna=True).apply(lambda x: f(x))\n",
    "    df.loc[:,'SOFA_min_day'] = df_dofas[sofa_cols].idxmin(axis=1,skipna=True).apply(lambda x: f(x))\n",
    "    \n",
    "    df.loc[:,'SOFA_range'] = df['SOFA_max_day']-df['SOFA_min_day']\n",
    "    df.loc[:,'SOFA_long_stay'] = (~df_dofas[sofa_cols].isna()).sum(axis=1)\n",
    "\n",
    "    merge_list = ['SOFA']\n",
    "    merge_list_calc = []\n",
    "    tick_list = cols2[1:-1]\n",
    "    for item_list in merge_list:\n",
    "        buffer_pre,buffer_post = build_set(item_list,n+1)\n",
    "        tick_list = [*tick_list,*buffer_pre,item_list,*buffer_post]\n",
    "    for item_list in merge_list_calc:\n",
    "        buffer_pre,buffer_post = build_set(item_list,n)\n",
    "        tick_list = [*tick_list,*buffer_pre,item_list,*buffer_post]\n",
    "\n",
    "    tick_list=[*tick_list,'TotalAUC','SOFA_max','SOFA_min','SOFA_max_day','SOFA_min_day','SOFA_range','SOFA_long_stay']\n",
    "    df = df.fillna(0).reset_index()\n",
    "    \n",
    "    le = {}\n",
    "    for k in ['insurance','marital_status','race','gender']:\n",
    "        le[k] = LabelEncoder()\n",
    "        df[k] = le[k].fit_transform(df[k].astype(str))\n",
    "    \n",
    "    x = df.drop(columns=['id','id','index','30d_mortality_status'])\n",
    "    y = df['30d_mortality_status']\n",
    "    \n",
    "    feat_set = list(x.columns)\n",
    "    feat_dic = {j:i for i,j in enumerate(feat_set)}\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    feat_list = []\n",
    "    feature_importances_list = []\n",
    "    accs[count] = []\n",
    "    accs_eff = []\n",
    "    baccs[count] = []\n",
    "    f1s[count] = []\n",
    "    prs[count] = []\n",
    "    recs[count] = []\n",
    "    rocs[count] = []\n",
    "    cms[count] = []\n",
    "    \n",
    "    for i_try in range(5):\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            x_train,y_train = balance_data(x_train,y_train)\n",
    "            \n",
    "            clf = RandomForestClassifier()\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            pr = precision_score(y_test,y_pred)\n",
    "            rec = recall_score(y_test,y_pred)\n",
    "            roc = roc_auc_score(y_test,y_pred)\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            \n",
    "            accs[count].append(acc)\n",
    "            accs_eff.append(acc)\n",
    "            baccs[count].append(bacc)\n",
    "            f1s[count].append(f1)\n",
    "            prs[count].append(pr)\n",
    "            recs[count].append(rec)\n",
    "            rocs[count].append(roc)\n",
    "            cms[count].append(cm)\n",
    "            \n",
    "            feat_list.extend(feat_set)\n",
    "            feature_importances_list.append(clf.feature_importances_)\n",
    "            accs_eff.append(clf.score(x_test,y_test))\n",
    "    \n",
    "    feat_x = [feat_dic[i] for i in feat_list]\n",
    "    print(n, np.mean(accs_eff),np.std(accs_eff))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=np.mean(np.array(cms[count]),axis=(0)).astype(int),display_labels=[0,1])\n",
    "    disp.plot()\n",
    "    plt.savefig('images/cm_dem{}.tif'.format(n),dpi=300)\n",
    "    ;\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(18,6))\n",
    "    ax.scatter(feat_x,feature_importances_list,marker='.')\n",
    "    ax.set_ylabel('feature importances')\n",
    "    ax.set_xticks(np.arange(len(feat_set)))\n",
    "    ax.set_xticklabels(tick_list, rotation=90)\n",
    "    ax.set_xlim(-0.5,len(feat_set)-0.5)\n",
    "    \n",
    "    title = ''\n",
    "    title += f'acc={np.mean(accs_eff):.2f}({np.std(accs_eff):.2f}), '\n",
    "    title += f'balanced acc={np.mean(baccs[count]):.2f}({np.std(baccs[count]):.2f}), '\n",
    "    title += f'f1={np.mean(f1s[count]):.2f}({np.std(f1s[count]):.2f})\\n'\n",
    "    title += f'precision={np.mean(prs[count]):.2f}({np.std(prs[count]):.2f}), '\n",
    "    title += f'recall={np.mean(recs[count]):.2f}({np.std(recs[count]):.2f}), '\n",
    "    title += f'ROC={np.mean(rocs[count]):.2f}({np.std(rocs[count]):.2f})'\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    plt.subplots_adjust(bottom=0.36)\n",
    "    plt.savefig('images/set_dem{}.tif'.format(n),dpi=300)\n",
    "    ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25cd2a9-ea95-467c-ab86-c0809a51e9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in [3,8]:\n",
    "    count = count + 1\n",
    "    sofa_cols = sofa_ds[0:n+1]\n",
    "    param_list =sofa_cols\n",
    "    \n",
    "    df_dofas = df_base[['id',*sofa_cols]].copy()\n",
    "    df_dofas = df_dofas.dropna(how='all', subset = sofa_cols) \n",
    "    \n",
    "    df = df_base[[\n",
    "        'id',*cols2,*param_list\n",
    "    ]].copy()\n",
    "    \n",
    "    df.loc[:,'TotalAUC'] = df_base[auc[0:n]].sum(axis=1)\n",
    "    df.loc[:,'SOFA_max'] = df_dofas[sofa_cols].max(axis=1)\n",
    "    df.loc[:,'SOFA_min'] = df_dofas[sofa_cols].min(axis=1)\n",
    "    def f(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        return int(x.replace('SOFA_d',''))\n",
    "    df.loc[:,'SOFA_max_day'] = df_dofas[sofa_cols].idxmax(axis=1,skipna=True).apply(lambda x: f(x))\n",
    "    df.loc[:,'SOFA_min_day'] = df_dofas[sofa_cols].idxmin(axis=1,skipna=True).apply(lambda x: f(x))\n",
    "    \n",
    "    df.loc[:,'SOFA_range'] = df['SOFA_max_day']-df['SOFA_min_day']\n",
    "    df.loc[:,'SOFA_long_stay'] = (~df_dofas[sofa_cols].isna()).sum(axis=1)\n",
    "\n",
    "    merge_list = ['SOFA']\n",
    "    merge_list_calc = []\n",
    "    tick_list = []\n",
    "    for item_list in merge_list:\n",
    "        buffer_pre,buffer_post = build_set(item_list,n+1)\n",
    "        tick_list = [*tick_list,*buffer_pre,item_list,*buffer_post]\n",
    "    for item_list in merge_list_calc:\n",
    "        buffer_pre,buffer_post = build_set(item_list,n)\n",
    "        tick_list = [*tick_list,*buffer_pre,item_list,*buffer_post]\n",
    "\n",
    "    tick_list=[*tick_list,'TotalAUC','SOFA_max','SOFA_min','SOFA_max_day','SOFA_min_day','SOFA_range','SOFA_long_stay']\n",
    "    df = df.fillna(0).reset_index()\n",
    "\n",
    "    x = df.drop(columns=['id','id', 'insurance', 'marital_status', 'race', 'gender',\n",
    "       'admission_age', 'weight', 'height','charlson_comorbidity_index','index','30d_mortality_status'])\n",
    "    y = df['30d_mortality_status']\n",
    "    \n",
    "    feat_set = list(x.columns)\n",
    "    feat_dic = {j:i for i,j in enumerate(feat_set)}\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    feat_list = []\n",
    "    feature_importances_list = []\n",
    "    accs[count] = []\n",
    "    accs_eff = []\n",
    "    baccs[count] = []\n",
    "    f1s[count] = []\n",
    "    prs[count] = []\n",
    "    recs[count] = []\n",
    "    rocs[count] = []\n",
    "    cms[count] = []\n",
    "    \n",
    "    for i_try in range(5):\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            x_train,y_train = balance_data(x_train,y_train)\n",
    "            \n",
    "            clf = RandomForestClassifier()\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            bacc = balanced_accuracy_score(y_test,y_pred)\n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            pr = precision_score(y_test,y_pred)\n",
    "            rec = recall_score(y_test,y_pred)\n",
    "            roc = roc_auc_score(y_test,y_pred)\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            \n",
    "            accs[count].append(acc)\n",
    "            accs_eff.append(acc)\n",
    "            baccs[count].append(bacc)\n",
    "            f1s[count].append(f1)\n",
    "            prs[count].append(pr)\n",
    "            recs[count].append(rec)\n",
    "            rocs[count].append(roc)\n",
    "            cms[count].append(cm)\n",
    "            \n",
    "            feat_list.extend(feat_set)\n",
    "            feature_importances_list.append(clf.feature_importances_)\n",
    "            accs_eff.append(clf.score(x_test,y_test))\n",
    "    \n",
    "    feat_x = [feat_dic[i] for i in feat_list]\n",
    "    print(n, np.mean(accs_eff),np.std(accs_eff))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=np.mean(np.array(cms[count]),axis=(0)).astype(int),display_labels=[0,1])\n",
    "    disp.plot()\n",
    "    plt.savefig('images/cm_sofa{}.tif'.format(n),dpi=300)\n",
    "    ;\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(18,6))\n",
    "    ax.scatter(feat_x,feature_importances_list,marker='.')\n",
    "    ax.set_ylabel('feature importances')\n",
    "    ax.set_xticks(np.arange(len(feat_set)))\n",
    "    ax.set_xticklabels(tick_list, rotation=90)\n",
    "    ax.set_xlim(-0.5,len(feat_set)-0.5)\n",
    "    \n",
    "    title = ''\n",
    "    title += f'acc={np.mean(accs_eff):.2f}({np.std(accs_eff):.2f}), '\n",
    "    title += f'balanced acc={np.mean(baccs[count]):.2f}({np.std(baccs[count]):.2f}), '\n",
    "    title += f'f1={np.mean(f1s[count]):.2f}({np.std(f1s[count]):.2f})\\n'\n",
    "    title += f'precision={np.mean(prs[count]):.2f}({np.std(prs[count]):.2f}), '\n",
    "    title += f'recall={np.mean(recs[count]):.2f}({np.std(recs[count]):.2f}), '\n",
    "    title += f'ROC={np.mean(rocs[count]):.2f}({np.std(rocs[count]):.2f})'\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    plt.subplots_adjust(bottom=0.36)\n",
    "    plt.savefig('images/set_sofa{}.tif'.format(n),dpi=300)\n",
    "    ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967071e-143b-4457-b649-fd15f33f73a8",
   "metadata": {},
   "source": [
    "# Spider plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524df18c-76be-43d7-b05a-102bf15f3c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "set_list = ['3 days All','8 days All','3 days dem','8 days dem','3 days SOFA','8 days SOFA']\n",
    "for k in range(6):\n",
    "    #kk = np.stack([accs[k],baccs[k],f1s[k],prs[k],recs[k],rocs[k]],axis=0)\n",
    "    cm3 = np.array(cms[k])\n",
    "    tn = cm3[:,0,0]\n",
    "    fp = cm3[:,0,1]\n",
    "    fn = cm3[:,1,0]\n",
    "    tp = cm3[:,1,1]\n",
    "    npv = tn/(fn+tn)\n",
    "    spec = 2*np.array(baccs[k]) - np.array(recs[k])\n",
    "    kk = np.stack([recs[k],2*np.array(prs[k]),spec,npv,rocs[k]],axis=0)\n",
    "    metrics.append(kk)\n",
    "metrics = np.mean(np.stack(metrics,axis=0),axis=2)\n",
    "#metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76bafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle', 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "\n",
    "    class RadarTransform(PolarAxes.PolarTransform):\n",
    "\n",
    "        def transform_path_non_affine(self, path):\n",
    "            # Paths with non-unit interpolation steps correspond to gridlines,\n",
    "            # in which case we force interpolation (to defeat PolarTransform's\n",
    "            # autoconversion to circular arcs).\n",
    "            if path._interpolation_steps > 1:\n",
    "                path = path.interpolated(num_vars)\n",
    "            return Path(self.transform(path.vertices), path.codes)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        PolarTransform = RadarTransform\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta\n",
    "\n",
    "# Precision = PPV\n",
    "# Recall = Sensitivity\n",
    "spoke_labels = ['Sensitivity','2xPPV',  'Specificity', 'NPV','ROC']\n",
    "\n",
    "theta = radar_factory(len(spoke_labels), frame='polygon')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5), nrows=1, ncols=1,\n",
    "                        subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)\n",
    "\n",
    "#colors = ['b', 'r', 'g', 'm', 'y','k']\n",
    "colors = ['b', 'b', 'r','r', 'm','m']\n",
    "linestyles = ['dotted','solid','dotted','solid','dotted','solid']\n",
    "# Plot the six cases from the example data on separate axes\n",
    "\n",
    "title = 'Model Comparison'\n",
    "case_data = metrics\n",
    "\n",
    "ax.set_rgrids([0.4, 0.5, 0.6, 0.7, 0.8], angle=90)\n",
    "ax.set_title(title, weight='bold', size='medium', position=(0.5, 1.1),\n",
    "             horizontalalignment='center', verticalalignment='center')\n",
    "for d, color,linestyle in zip(case_data, colors,linestyles):\n",
    "    ax.plot(theta, d, color=color, linestyle=linestyle)\n",
    "    #ax.fill(theta, d, facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "ax.set_varlabels(spoke_labels)\n",
    "ax.set_ylim([0.5,1])\n",
    "\n",
    "# add legend relative to top-left plot\n",
    "labels = set_list\n",
    "legend = ax.legend(labels, loc=(0.9, .95),\n",
    "                          labelspacing=0.1, fontsize='small')\n",
    "plt.savefig('images/spider.tif',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8952399-3d6b-4260-a348-919f6ea94826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
